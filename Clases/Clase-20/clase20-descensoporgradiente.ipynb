{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a162ccb0b4cf66ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from formulaic import Formula\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968b1f89",
   "metadata": {},
   "source": [
    "Instalar las siguientes librerias y reiniciar el kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d7a0c16b8669",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974a9ef",
   "metadata": {},
   "source": [
    "Para Windows (descomentar y ejecutar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139672eeda96e2ef",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0812dbb3",
   "metadata": {},
   "source": [
    "Para Linux (decomentar y ejecutar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af417f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271934d4267637bd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Descenso Por Gradiente\n",
    "\n",
    "### Laboratorio de Datos, IC - FCEN - UBA - 1er. Cuatrimestre 2024\n",
    "\n",
    "Importamos el Regresor basado en Tensorflow y Keras. Ya viene implementado con Descenso por Gradiente y Descenso por \n",
    "Gradiente Estocástico. Sirve para hacer Regresión (Lineal y no Lineal) y para clasificación con Regresión Logística.\n",
    "\n",
    "También importamos la función ``train_test_split_scale_center`` que separa los datos en entrenamiento y testeo, aplica ``MinMaxScaler`` y, opcionalmente, los\n",
    "centra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c015239533028f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tf_regressor import Regressor, train_test_split_scale_center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d638f8390a9a7f1a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Motivación 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c7e98fbe1c34ab",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Resolver sistemas de ecuaciones *grandes* es computacionalmente costoso. Veamos un ejemplo, con un dataset sintético \n",
    "de $11000$ observaciones de $10000$ features cada una (un total de $110$ millones de valores).\n",
    "\n",
    "Utilizamos el modelo:\n",
    "$$Y = \\beta_0 + \\sum_{i=1}^{10000} \\beta_iX_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f318cad5d9854ea",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Generamos 11000 muestras aleatorias con 10000 features cada una\n",
    "np.random.seed(11)\n",
    "n, m = 11000, 10000\n",
    "mega_X = np.random.randn(n, m)\n",
    "simulation_weights = np.random.randint(3, size=mega_X.shape[1])\n",
    "mega_Y = (mega_X @ simulation_weights + np.random.randn(int(n)) / 10).reshape(-1, 1) # reshape para volverlo una columna\n",
    "\n",
    "# Normalizamos los datos y los centramos\n",
    "mega_X_train, mega_X_test, mega_y_train, mega_y_test = train_test_split_scale_center(mega_X, mega_Y,\n",
    "                                                                                     transform_y=True,\n",
    "                                                                                     test_size=0.2,\n",
    "                                                                                     random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d8cf5",
   "metadata": {},
   "source": [
    "<font color='red'>**CUIDADO AL CORRER ESTO, PUEDE EXPLOTAR**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445085abc0e5a5bc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Hacemos regresion lineal con scikit-learn\n",
    "model = linear_model.LinearRegression()\n",
    "start = time()  # marcamos el tiempo de inicio del entrenamiento\n",
    "model.fit(mega_X_train, mega_y_train)\n",
    "tiempo_matricial = time() - start   # registramos el tiempo total de entrenamiento\n",
    "mse_matricial = mean_squared_error(mega_y_test, model.predict(mega_X_test))\n",
    "print('Tiempo total de entrenamiento: ', tiempo_matricial)\n",
    "print('MSE en conjunto de testeo: ', mse_matricial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6de53553de19c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Motivación 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a7192186d91dc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Tenemos un dataset con la evolución de nuevos casos diarios de COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f613bcbcbbe4984",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "coro = pd.read_csv('casos_coronavirus.csv')\n",
    "coro.reset_index(inplace=True)      # Reseteamos el índice para trabajar con los indices en vez de las fechas\n",
    "so.Plot(data=coro, x='index', y='confirmados_Nuevos').add(so.Dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8452c9d51c48c1d0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "¿Qué tipo de función parece que sigue la evolución de los casos? ¿Podemos plantear un modelo de regresión **lineal**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f210972d160e8b4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1. Ejemplo: Regresión Lineal con una variable predictora "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa701d2dec7bbe2e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Usemos el dataset de ``inmuebles.csv`` para hacer regresión lineal del precio a partir de la superficie del inmueble:\n",
    "$$precio = b + w\\cdot superficie \\qquad (precio \\sim superficie) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c28cbf26559759b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Cargamos el dataset\n",
    "data = pd.read_csv('inmuebles.csv')\n",
    "\n",
    "# Normalizamos los datos\n",
    "X = data['superficie']\n",
    "y = data['precio']\n",
    "X_train, X_test, y_train, y_test = train_test_split_scale_center(X, y, \n",
    "                                                                 transform_y=True,  # Normalizamos y también \n",
    "                                                                 center=False,      # No centramos los datos\n",
    "                                                                 test_size=0.2,     # 20% de los datos para testeo\n",
    "                                                                 random_state=11)   # Semilla para datos de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8128e6fc84146aa",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Definimos la funcion del modelo (x, w, b deben respetar ese orden en la declaracion de lambda)\n",
    "f = lambda x, w, b: b + w*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff4705783d6d06",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inicializamos el modelo (por ahora no tiene nada)\n",
    "model = Regressor()\n",
    "\n",
    "# Le agregamos la funcion y especificamos la dimension de w \n",
    "model.add_f(f,                  # funcion del modelo \n",
    "            dim_w=1,            # dimension de w\n",
    "            random_state=21,    # semilla para selecciones aleatorias\n",
    "            opt='gd'            # Especificamos que usamos descenso por gradiente\n",
    "            )\n",
    "\n",
    "# Entrenamos el modelo con los conjuntos de entrenamiento\n",
    "model.fit_(X_train, y_train,        # Conjuntos de entrenamiento \n",
    "           epochs=200,              # Cantidad de epocas\n",
    "           validation_split=0.2,    # 20% de datos para validacion\n",
    "           learning_rate=0.05)      # Learning rate inicial      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf37ad179b2f92",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Imprimimos los pesos y el bias resultantes del entrenamiento\n",
    "print(model.weights_)\n",
    "print(model.bias_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93867b7a8804e75e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluamos el MSE en el conjunto de testeo\n",
    "model.evaluate(X_test.to_numpy(), y_test.to_numpy(),        # A TensorFlow no le gustan los DataFrame de pandas \n",
    "               return_dict=True,                            # Devuelve un diccionario (por si usamos mas de una métrica)\n",
    "               verbose=0,                                   # No imprima en pantalla el procedimiento de evaluación\n",
    "               batch_size=len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d37bbe2f8c1c8f9",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Podemos graficar la evolución de la función de pérdida (MSE)\n",
    "model.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1023c291b781cd23",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Podemos graficar como evolucionó el algoritmo a través de las épocas\n",
    "model.plot_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7965203092da2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Y ver una animación de cómo fue evolucionando la regresión\n",
    "model.animate_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef421a281909f251",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Obs:** el desempeño y el resultado del algoritmo dependen de la elección de pesos y bias inciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36883598383dca0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model2 = Regressor()\n",
    "\n",
    "# Volvamos a entrenar el modelo proporcionándole pesos y bias iniciales\n",
    "model2.add_f(f,                 # funcion del modelo \n",
    "            w0=1,               # peso inicial\n",
    "            b0=0,               # bias inicial\n",
    "            opt='gd',            # Especificamos que usamos descenso por gradiente\n",
    "            random_state=21,    # semilla para selecciones aleatorias\n",
    "            )\n",
    "\n",
    "# Entrenamos el modelo con los conjuntos de entrenamiento\n",
    "model2.fit_(X_train, y_train,        # Conjuntos de entrenamiento \n",
    "           epochs=200,              # Cantidad de epocas\n",
    "           validation_split=0.2,    # 20% de datos para validacion\n",
    "           learning_rate=0.05)      # Learning rate inicial   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1069c5f5f149a93f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluamos el MSE en el conjunto de testeo\n",
    "model2.evaluate(X_test.to_numpy(), y_test.to_numpy(),        # A TensorFlow no le gustan los DataFrame de pandas \n",
    "               return_dict=True,                            # Devuelve un diccionario (por si usamos mas de una métrica)\n",
    "               verbose=0,                                   # No imprima en pantalla el procedimiento de evaluación\n",
    "               batch_size=len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5affa2bf0a9f38ff",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model2.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f9fcb1-fc08-4c14-95c0-6f8bbd929162",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.animate_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53611f4da87fed9b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 2. Ejemplo: Regresión Lineal con más de una variable predictora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ade25423b8cb7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Vamos a tratar de predecir el peso de los pingüinos según la longitud de su pico y la de su aleta, y su interacción:\n",
    "$$body\\_mass\\_g = b + w_0\\cdot bill\\_length\\_mm + w_1\\cdot flipper\\_length\\_mm + \n",
    "w_2\\cdot bill\\_length\\_mm\\cdot flipper\\_length\\_mm$$\n",
    "o, escrito con la notación de Wilkinson-Rogers: \n",
    "$$body\\_mass\\_g \\sim bill\\_length\\_mm*flipper\\_length\\_mm$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d615b636a44e9",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cargamos el dataset\n",
    "penguins = sns.load_dataset('penguins')\n",
    "penguins.dropna(inplace=True)\n",
    "\n",
    "# Elegimos los features, separamos en entrenamiento y testeo y normalizamos\n",
    "X = penguins[['bill_length_mm', 'flipper_length_mm']]\n",
    "y = penguins['body_mass_g']\n",
    "X_train, X_test, y_train, y_test = train_test_split_scale_center(X, y, \n",
    "                                                                 transform_y=True,  # Normalizamos y también \n",
    "                                                                 center=False,      # No centramos los datos\n",
    "                                                                 test_size=0.2,     # 20% de los datos para testeo\n",
    "                                                                 random_state=11)   # Semilla para datos de testeo\n",
    "\n",
    "# Definimos la funcion del modelo\n",
    "f = lambda x, w, b: b + w[0]*x[:,0] + w[1]*x[:,1] + w[2]*x[:,0]*x[:,1] \n",
    "\n",
    "model3 = Regressor()\n",
    "\n",
    "# Volvamos a entrenar el modelo con pesos y bias iniciales aleatorios\n",
    "model3.add_f(f,                 # funcion del modelo\n",
    "            dim_w= 3,           # dimension de w\n",
    "            random_state=2077,  # semilla para selecciones aleatorias\n",
    "            opt='gd'            # Especificamos que usamos descenso por gradiente\n",
    "            )\n",
    "\n",
    "# Entrenamos el modelo con los conjuntos de entrenamiento\n",
    "model3.fit_(X_train, y_train,       # Conjuntos de entrenamiento \n",
    "           epochs=200,              # Cantidad de epocas\n",
    "           validation_split=0.2,    # 20% de datos para validacion\n",
    "           learning_rate=0.05)      # Learning rate inicial   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36052aefac798c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Imprimimos pesos y bias obtenidos con el entrenamiento\n",
    "print(model3.weights_)\n",
    "print(model3.bias_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef6efd38f997af",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos el MSE en el conjunto de testeo\n",
    "model3.evaluate(X_test.to_numpy(), y_test.to_numpy(),        # A TensorFlow no le gustan los DataFrame de pandas \n",
    "               return_dict=True,                            # Devuelve un diccionario (por si usamos mas de una métrica)\n",
    "               verbose=0,                                   # No imprima en pantalla el procedimiento de evaluación\n",
    "               batch_size=len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641e823948985b8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Graficamos la evolución del MSE\n",
    "model3.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ff51c0bed906c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3. Ejemplo: Regresión no lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d8f0ef3a6b95a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Vamos a realizar Regresión Logística para clasificar pingüinos según su especie (Gentoo o Chinstrap) a partir de su \n",
    "peso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a54dffc733757d0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Nos quedamos solo con los pingüinos Gentoo o Chinstrap\n",
    "penguins_clasif = penguins[penguins['species'].isin(['Chinstrap', 'Gentoo'])]\n",
    "\n",
    "X = penguins_clasif['body_mass_g']\n",
    "y = penguins_clasif['species']\n",
    "\n",
    "# Transformamos y a un vector de 1's y 0's:\n",
    "y = y.apply(lambda t: 1*(t == 'Gentoo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e38a6ed8aefed7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Graficamos los pesos según la especie\n",
    "(\n",
    "    so.Plot()\n",
    "    .add(so.Dot(), x=X, y=y.iloc[::-1], color=penguins_clasif['species'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929554d5653fd672",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# separamos en entrenamiento y testeo, normalizamos y centramos\n",
    "X_train, X_test, y_train, y_test = train_test_split_scale_center(X, y, \n",
    "                                                                 test_size=0.2,     # 20% de los datos para testeo\n",
    "                                                                 random_state=10)   # Semilla para datos de testeo\n",
    "\n",
    "# Definimos la funcion del modelo\n",
    "f = lambda x, w, b: 1 / (1 + np.e**(-(b + w*x)))\n",
    "\n",
    "model4 = Regressor()\n",
    "\n",
    "# Entrenamos el modelo proporcionándole pesos y bias iniciales\n",
    "model4.add_f(f,                  # funcion del modelo\n",
    "            w0 = 0,              # peso incial\n",
    "            b0 = 0,              # bias inicial\n",
    "            random_state=21,     # semilla para selecciones aleatorias\n",
    "            opt='gd'             # Especificamos que usamos descenso por gradiente\n",
    "            )\n",
    "\n",
    "# Entrenamos el modelo con los conjuntos de entrenamiento\n",
    "model4.fit_(X_train, y_train,       # Conjuntos de entrenamiento\n",
    "            classify=True,          # Indicamos que vamos a clasificar\n",
    "           epochs=50,              # Cantidad de epocas\n",
    "           validation_split=0.2,    # 20% de datos para validacion\n",
    "           learning_rate=0.5)       # Learning rate inicial  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374be229663bdb7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Imprimimos pesos y bias obtenidos con el entrenamiento\n",
    "print(model4.weights_)\n",
    "print(model4.bias_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc62b9b4eb81d6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos el BCE en el conjunto de testeo\n",
    "model4.evaluate(X_test.to_numpy(), y_test.to_numpy(),       # A TensorFlow no le gustan los DataFrame de pandas \n",
    "               return_dict=True,                            # Devuelve un diccionario (por si usamos mas de una métrica)\n",
    "               verbose=0,                                   # No imprima en pantalla el procedimiento de evaluación\n",
    "               batch_size=len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283fc3183a15acb9",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Graficamos la evolución del BCE\n",
    "model4.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb342ff8419d56f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos la prediccion del modelo para X_test\n",
    "y_pred = (model4.predict(X_test, verbose=0, batch_size=len(y_test)).flatten() > 0.5).astype('int')\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6262a25cc6e5f668",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Graficamos la clasificación\n",
    "(\n",
    "    so.Plot(x=X_test, y=y_test, color=y_pred)\n",
    "    .add(so.Dot())\n",
    "    .label(color='Clasificacion')\n",
    "    .scale(color={1: 'red', 0:'black'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9179d1ee876713a2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Animamos la regresion resultante en cada época\n",
    "model4.animate_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8cdbec5474f07",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 4. Ejemplo: Descenso por Gradiente Estocástico "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6a977089e685b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Rehacemos la clasificación anterior, pero usando SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77debfc9b977c53",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Definimos la funcion del modelo\n",
    "f = lambda x, w, b: 1 / (1 + np.e**(-(b + w*x)))\n",
    "\n",
    "model5 = Regressor()\n",
    "\n",
    "# Volvamos a entrenar el modelo, pero con SGD\n",
    "model5.add_f(f,                  # funcion del modelo\n",
    "            w0 = 0,              # peso incial\n",
    "            b0 = 0,              # bias inicial\n",
    "            random_state=21,     # semilla para selecciones aleatorias\n",
    "            )\n",
    "\n",
    "# Entrenamos el modelo con los conjuntos de entrenamiento\n",
    "model5.fit_(X_train, y_train,       # Conjuntos de entrenamiento\n",
    "            classify=True,          # Indicamos que vamos a clasificar\n",
    "            epochs=50,             # Cantidad de epocas\n",
    "            batch_size=1,           # tamaño del batch\n",
    "            validation_split=0.2,   # 20% de datos para validacion\n",
    "            learning_rate=0.5)      # Learning rate inicial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440182217a92356",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos el BCE en el conjunto de testeo\n",
    "model5.evaluate(X_test.to_numpy(), y_test.to_numpy(),       # A TensorFlow no le gustan los DataFrame de pandas \n",
    "               return_dict=True,                            # Devuelve un diccionario (por si usamos mas de una métrica)\n",
    "               verbose=0,                                   # No imprima en pantalla el procedimiento de evaluación\n",
    "               batch_size=len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0271ad1ae1da0f6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Comparado con el modelo de Descenso por Gradiente\n",
    "model4.evaluate(X_test.to_numpy(), y_test.to_numpy(),       # A TensorFlow no le gustan los DataFrame de pandas \n",
    "               return_dict=True,                            # Devuelve un diccionario (por si usamos mas de una métrica)\n",
    "               verbose=0,                                   # No imprima en pantalla el procedimiento de evaluación\n",
    "               batch_size=len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb92f85674442f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Graficamos la evolución del BCE\n",
    "model5.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca28af39f673a09",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos la prediccion del modelo para X_test y graficamos la clasificacion\n",
    "y_pred = (model5.predict(X_test, verbose=0, batch_size=len(y_test)).flatten() > 0.5).astype('int')\n",
    "(\n",
    "    so.Plot(x=X_test, y=y_test, color=y_pred)\n",
    "    .add(so.Dot())\n",
    "    .label(color='Clasificacion')\n",
    "    .scale(color={1: 'red', 0:'black'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be40926b99ce44",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Animamos la regresion resultante en cada época\n",
    "model5.animate_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce34906a7dbe66",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 5. Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c01a9fff55b542",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 5.1 Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb58271a6eae61",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Volvemos a trabajar con el dataset de pinguinos\n",
    "penguins = sns.load_dataset('penguins')\n",
    "penguins.dropna(inplace=True)\n",
    "\n",
    "# Elegimos los features, separamos en entrenamiento y testeo y normalizamos\n",
    "X = penguins[['bill_length_mm', 'flipper_length_mm']]\n",
    "y = penguins['body_mass_g']\n",
    "X_train, X_test, y_train, y_test = train_test_split_scale_center(X, y, \n",
    "                                                                 transform_y=True,  # Normalizamos y también \n",
    "                                                                 center=False,      # No centramos los datos\n",
    "                                                                 test_size=0.2,     # 20% de los datos para testeo\n",
    "                                                                 random_state=10)   # Semilla para datos de testeo\n",
    "\n",
    "# Definimos la funcion del modelo\n",
    "f = lambda x, w, b: b + w[0]*x[:,0] + w[1]*x[:,1] + w[2]*x[:,0]*x[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6006cf6ae623cf8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Consideramos el modelo con learning rate constante 0.05\n",
    "model_no_schedule = Regressor()\n",
    "\n",
    "# Inicializamos el modelo con pesos y bias iniciales aleatorios\n",
    "model_no_schedule.add_f(f,                  # funcion del modelo\n",
    "            dim_w= 3,           # dimension de w\n",
    "            random_state=2077,  # semilla para selecciones aleatorias\n",
    "            )\n",
    "\n",
    "# Entrenamos el modelo con los conjuntos de entrenamiento\n",
    "model_no_schedule.fit_(X_train, y_train,        # Conjuntos de entrenamiento \n",
    "           epochs=200,              # Cantidad de epocas\n",
    "           validation_split=0.2,    # 20% de datos para validacion\n",
    "            batch_size = 6,\n",
    "            verbose=0\n",
    "            )\n",
    "\n",
    "# Calculamos el error en el conjunto de testeo\n",
    "model_no_schedule.evaluate(X_test.to_numpy(), y_test.to_numpy(),        # A TensorFlow no le gustan los DataFrame de pandas \n",
    "               return_dict=True,                            # Devuelve un diccionario (por si usamos mas de una métrica)\n",
    "               verbose=0,                                   # No imprima en pantalla el procedimiento de evaluación\n",
    "               batch_size=len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b2adb6eb56ec5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Lo mismo pero con learning rate variable\n",
    "model_with_schedule = Regressor()\n",
    "\n",
    "# Definimos una funcion que disminuya el learning rate a medida que aumentan las epocas\n",
    "def schedule(epoch, learning_rate):\n",
    "    if epoch <= 10:\n",
    "        return learning_rate\n",
    "    else:\n",
    "        return learning_rate * (0.95 ** ((epoch + 1) % 10 == 0))\n",
    "    \n",
    "\n",
    "# Inicializamos el modelo con pesos y bias iniciales aleatorios\n",
    "model_with_schedule.add_f(f,      # funcion del modelo\n",
    "            dim_w= 3,           # dimension de w\n",
    "            random_state=2077,  # semilla para selecciones aleatorias\n",
    "            )\n",
    "\n",
    "# Entrenamos el modelo con los conjuntos de entrenamiento\n",
    "model_with_schedule.fit_(X_train, y_train,        # Conjuntos de entrenamiento \n",
    "           epochs=200,              # Cantidad de epocas\n",
    "           validation_split=0.2,    # 20% de datos para validacion\n",
    "           learning_rate=0.1,      # Learning rate inicial\n",
    "            lr_scheduler=schedule,  # Agregamos la funcion de schedule\n",
    "            batch_size = 6,\n",
    "            )\n",
    "\n",
    "# Calculamos el error en el conjunto de testeo\n",
    "model_with_schedule.evaluate(X_test.to_numpy(), y_test.to_numpy(),        # A TensorFlow no le gustan los DataFrame de pandas \n",
    "               return_dict=True,                            # Devuelve un diccionario (por si usamos mas de una métrica)\n",
    "               verbose=0,                                   # No imprima en pantalla el procedimiento de evaluación\n",
    "               batch_size=len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaa95e407afcbff",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 5.2 Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e71cea9f0554c97",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Agregamos ahora early stopping para que el entrenamiento pare si el MSE no mejora en varias epocas\n",
    "model_with_schedule_and_es = Regressor()\n",
    "\n",
    "# Inicializamos el modelo con pesos y bias iniciales aleatorios\n",
    "model_with_schedule_and_es.add_f(f,      # funcion del modelo\n",
    "            dim_w= 3,           # dimension de w\n",
    "            random_state=2077,  # semilla para selecciones aleatorias\n",
    "            )\n",
    "\n",
    "# Entrenamos el modelo con los conjuntos de entrenamiento\n",
    "model_with_schedule_and_es.fit_(X_train, y_train,        # Conjuntos de entrenamiento \n",
    "           epochs=200,              # Cantidad de epocas\n",
    "           validation_split=0.2,    # 20% de datos para validacion\n",
    "           learning_rate=0.1,      # Learning rate inicial\n",
    "            lr_scheduler=schedule,  # Agregamos la funcion de schedule\n",
    "            batch_size = 6,\n",
    "            early_stopping=True,     # Activamos el early stopping\n",
    "            start_from_epoch=50,    # Entra en funcionamiento a partir de la epoca 50\n",
    "            patience=30,            # Si en 30 epocas el MSE no mejora, para\n",
    "            )\n",
    "\n",
    "# Calculamos el error en el conjunto de testeo\n",
    "model_with_schedule_and_es.evaluate(X_test.to_numpy(), y_test.to_numpy(),        # A TensorFlow no le gustan los DataFrame de pandas \n",
    "               return_dict=True,                            # Devuelve un diccionario (por si usamos mas de una métrica)\n",
    "               verbose=0,                                   # No imprima en pantalla el procedimiento de evaluación\n",
    "               batch_size=len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb3d658b02a33e5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 6. Comparación con resolución matricial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404e4a9aa00bd79",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Ahora con SGD\n",
    "model = Regressor()\n",
    "# f = lambda x, w, b: b + sum(w[i] * x[:, i] for i in range(len(w)))\n",
    "f = lambda x, w, b: b + tf.linalg.matvec(x,w)\n",
    "model.add_f(f, \n",
    "           w0=np.zeros(mega_X_train.shape[1]),\n",
    "           b0=0,\n",
    "           random_state=21\n",
    ")\n",
    "\n",
    "start = time()\n",
    "model.fit_(mega_X_train, mega_y_train,\n",
    "           batch_size=100,\n",
    "           epochs=200,             # Cantidad de epocas\n",
    "           verbose=0,              # No imprime progreso\n",
    "           clipnorm=2,             # Normaliza el gradiente\n",
    "           validation_split=0.2)   # 20% de datos para validacion)\n",
    "\n",
    "tiempo_SGD = time() - start\n",
    "print('Tiempo total de entrenamiento: ', tiempo_SGD)\n",
    "\n",
    "loss_dict = model.evaluate(mega_X_test.to_numpy(), mega_y_test.to_numpy(),   # A TensorFlow no le gustan los \n",
    "                           # DataFrame de \n",
    "                           # pandas \n",
    "               return_dict=True,                            # Devuelve un diccionario (por si usamos mas de una métrica)\n",
    "               verbose=0,                                   # No imprima en pantalla el procedimiento de evaluación\n",
    "               batch_size=len(mega_y_test))\n",
    "mse_SGD = loss_dict['loss']\n",
    "print('MSE en conjunto de testeo: ', mse_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427005a67c321a4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('Tiempo total de entrenamiento: ', tiempo_matricial)\n",
    "print('MSE en conjunto de testeo: ', mse_matricial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0b910b-e6c4-4d18-82d4-2f332b62ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'En {100*(tiempo_SGD / tiempo_matricial):.2f}% de tiempo, SGD obtuvo una solucion con {100*(mse_SGD / mse_matricial-1):.2f}% mas error cuadratico medio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6870bd39-ab7e-4aad-b789-a2ca3722628d",
   "metadata": {},
   "source": [
    "### 7. Incluyendo `formulaic`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9650f9-c37d-4db8-a94b-e0d05c2956ac",
   "metadata": {},
   "source": [
    "A veces podríamos querer usar `formulaic` para modelos **lineales** más complejos. Como ejemplo, supongamos que queremos aproximar el precio de un inmueble con un modelo de la forma:\n",
    "$$precio = b + w_1e^{superficie} + w_2\\,zona$$\n",
    "\n",
    "Para esto nos vendría bien usar `formulaic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d306db-441b-4a42-a22b-eba95d305140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset\n",
    "data = pd.read_csv('inmuebles.csv')\n",
    "\n",
    "# Transformamos los datos segun la formula (le dejamos el intercept a LinearRegression o a Regressor)\n",
    "y, X = Formula('precio~np.exp(superficie)+zona-1').get_model_matrix(data)\n",
    "\n",
    "# Normalizamos los datos (no los centramos para no alterar las variables dummy) y dividimos en entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split_scale_center(X, y, \n",
    "                                                                 transform_y=True,  # Normalizamos y también \n",
    "                                                                 center=False,      # No centramos los datos\n",
    "                                                                 test_size=0.2,     # 20% de los datos para testeo\n",
    "                                                                 random_state=11)   # Semilla para datos de testeo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0815025d-8fbc-4c58-8a43-01acf9f330af",
   "metadata": {},
   "source": [
    "#### 7.1 Con `LinearRegression` de `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d636a3d-4027-4fa8-933c-d87be98fcd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos la regresion con los datos transformados\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculamos el error cuadratico medio\n",
    "mean_squared_error(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcfb6b6-53de-4283-be3b-d6e98a4549fa",
   "metadata": {},
   "source": [
    "#### 7.2 Con `Regressor` de `tf_regressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32145537-8b72-47fe-bf1f-776637006bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribimos la funcion del modelo, teniendo en cuenta a que corresponde cada columna de X_train:\n",
    "# Columna 0: e^superficie\n",
    "# Columnas 1 a 3: variables dummy para 'zona'\n",
    "f = lambda x, w, b: b + w[0]*x[:,0] + w[1]*x[:,1] + w[2]*x[:,2] + w[3]*x[:,3]\n",
    "\n",
    "model = Regressor()\n",
    "\n",
    "model.add_f(f,                  # funcion del modelo\n",
    "            w0=np.zeros(4),     # Vector inicial de 0's de longitud 4\n",
    "            b0=0,\n",
    "            random_state=21,\n",
    "            )\n",
    "\n",
    "# Entrenamos el modelo con los conjuntos de entrenamiento\n",
    "model.fit_(X_train, y_train,\n",
    "           epochs=200,              \n",
    "           validation_split=0.2,      \n",
    "           learning_rate=0.05,\n",
    "           batch_size=5,\n",
    "           verbose=0)\n",
    "\n",
    "model.evaluate(X_test.to_numpy(), y_test.to_numpy(),\n",
    "               return_dict=True,                            \n",
    "               verbose=0,                                   \n",
    "               batch_size=len(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
